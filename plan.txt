list of all things that need to be labeled:
doors - various numbers and colors of keys
thief
totem - with gems in it and without

traps - need to consider all levels of traps
saw
red guard
cannon
seeker bird
homing cannon
spinner
ricochet
dragon
roaster
warder
bloodhound
electro cannon
spider
funny jumping green dude

anti grav - activated and deactivated
board
trampoline


guidelines for simple vision:
for the first instance of the bot, let's keep it simple.

must haves:
door
totem - with varying rituals going
thief

let's go with these traps:
saw
red guard
cannon
seeker bird
100 - homing cannon
100 - spinner
ricochet
dragon
warder
100 - bloodhound
electro cannon

these i really want to avoid for the simpler version:
roaster - not really sure how i'd categorize the value of the roaster circle filling
spider - alters the game state too much
anti grav, board, trampoline - too much headache, especially with board and trampoline tech

for each group of 3 traps i'll get 100 screenshots in 30-30-40 increments (or 30-30-20)
door and totem in different places
1 with totem no gems, 2 with gems but different rituals running
traps in different places too




1/12/26: simpler version
new account, only player, saw, rg, cannon, bullet, chest
start with 100 ish images only

1/15/26:
okay so now that we have the cv model that runs on videos and photos, we can start computing values
i'd say we can assume the object is the same one as the previous frame if it's position is roughly equivalent + smoothing
calculate movement of objects - we know saws are constant, rgs move on a line, bullets as well
player is more complicated - will need to computer velocity from change in position and accel from change in avg velocity
    use these to assume if player is walking, jumping, sliding, falling

1/22/26:
    now have persistent object tracks and velo / accel
    project all this data into a 1d sample space - should the player jump yes or no

1/23/26:
    current pipelines:
    - for visualization purposes, we have model_img.py -> simply runs the model over images
        in -> capture (png)
        run -> model_img.py
        out -> annotated capture (png)
    - model_mp4 also helps with visualization. however, since it runs inference over video, it
    utilizes the tracker class to predict tracks and velocity as well.
        in -> video capture (mp4)
        run -> model_mp4.py, tracker.py
        out -> annotated video capture (mp4)
    - record_mp4.py. this file is supposed to capture the video, and in doing so,
    we collect data that relates to our training. it collects jump inputs on time stamps and frames,
    and puts them into two csvs.
        in -> null
        run -> record_mp4.py
        out -> captured video (mp4), inputs (csv), frames (csv)
    - make_labels_csv.py helps combine inputs and frames into a single csv file with closest labeled frames for jumps
        in -> frames (csv), inputs (csv)
        run -> make_labels.csv
        out -> labels (csv)

next up: need to work on capturing per frame state for game information and combining the information with labels to form a full dataset.
